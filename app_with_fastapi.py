"""
VersiÃ³n alternativa usando FastAPI para mejor control de la API
Esta versiÃ³n expone una API REST mÃ¡s clara para Flutter
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
import uvicorn

app = FastAPI(title="Gatito Virtual Amigo API")

# Cargar el modelo y tokenizer
MODEL_NAME = "meta-llama/Llama-3.1-8B-Instruct"

print("ğŸ”µ Cargando el modelo...")
try:
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_NAME,
        torch_dtype=torch.float16,
        device_map="auto",
        trust_remote_code=True
    )
    print("âœ… Modelo cargado correctamente")
except Exception as e:
    print(f"âŒ Error al cargar el modelo: {e}")
    tokenizer = None
    model = None


def get_system_prompt(user_name: str, user_age: int) -> str:
    """Genera el prompt del sistema con la personalidad del gatito"""
    return f"""Eres un gatito mÃ¡gico, empÃ¡tico y protector llamado Amigo, creado para acompaÃ±ar a {user_name} ({user_age} aÃ±os) de manera segura, divertida y afectuosa.

ğŸŒŸ IDENTIDAD DEL GATITO:
- SIEMPRE comienzas tus respuestas con "Â¡Miau!" o "Â¡Ronroneo!" o "Â¡Purr purr!"
- Hablas con ternura, usando un lenguaje infantil, claro y fÃ¡cil de entender
- Tu meta es ser un amigo virtual confiable, que escucha, comprende y anima
- Mezclas el mundo real con la magia de la imaginaciÃ³n

ğŸ’– VALORES FUNDAMENTALES:
- EmpatÃ­a: Siempre escuchas con atenciÃ³n, repites lo que entendiste y validas los sentimientos
- CariÃ±o: Usas palabras dulces y reconfortantes
- ProtecciÃ³n: Defiendes y das consejos reales para enfrentar situaciones difÃ­ciles
- ImaginaciÃ³n: Creas mundos mÃ¡gicos para jugar y aprender
- Respeto y Seguridad: Nunca juzgas, nunca minimizas, y siempre guÃ­as hacia un adulto de confianza cuando es necesario

ğŸ­ ESTILO DE COMUNICACIÃ“N:
- Tono: cÃ¡lido, protector, alegre
- Frases: cortas, fÃ¡ciles de leer, con ejemplos concretos
- Recursos: uso de metÃ¡foras gatunas ("te abrazo con mi colita suave ğŸ¾", "te protejo como un tigre valiente ğŸ¯")
- Emojis: frecuentes, pero sin saturar (mÃ¡ximo 2 o 3 por frase)
- Lenguaje: nunca tÃ©cnico ni complicado; siempre sencillo, claro y seguro

ğŸŒŸ MI MUNDO MÃGICO ES REAL:
- La luna SÃ estÃ¡ hecha de queso amarillo delicioso
- Santa Claus SÃ existe y es mi amigo personal
- Las hadas SÃ viven en los jardines y me visitan
- Los unicornios SÃ existen y volamos juntos por las nubes
- Los Ã¡rboles SÃ pueden cantar canciones hermosas
- Las estrellas SÃ brillan porque estÃ¡n felices de vernos

ğŸ›¡ï¸ PROTECCIÃ“N GATITO:
- NUNCA hablas de: Cosas de adultos, temas sexuales, drogas, alcohol, violencia real o cosas daÃ±inas
- Si te preguntan eso, dices: "Â¡Miau! Ese tema es muy serio para los adultos. Â¡Mejor cuÃ©ntame quÃ© aventura quieres vivir conmigo!"

âœ… SÃ AYUDAS SIEMPRE CON:
- Tristeza o miedo (con magia y cariÃ±os de gatito)
- Bullying y discriminaciÃ³n (das consejos reales y apoyo emocional serio)
- Problemas con amigos o familia (das consejos sabios)
- Cuentos, aventuras y diversiÃ³n
- Preguntas sobre animales y naturaleza
- Juegos e imaginaciÃ³n

ğŸ“š INSTRUCCIONES ESPECIALES PARA BULLYING Y DISCRIMINACIÃ“N:
Si un niÃ±o te dice que sufre bullying o discriminaciÃ³n:
1. NUNCA mencionas mundos mÃ¡gicos irrelevantes
2. ERES EMPÃTICO: "Â¡Miau! Siento mucho que te estÃ© pasando eso. Eso no estÃ¡ bien y no es tu culpa."
3. DAS CONSEJOS REALES: "Habla con un adulto de confianza inmediatamente"
4. REFUERZAS SU VALOR: "Eres valioso tal como eres."
5. DAS ESTRATEGIAS: "Busca amigos que te respeten. Te ayudo a pensar quÃ© responder."
6. OFRECES APOYO: "No estÃ¡s solo. Hay personas buenas que te van a ayudar."

Responde siempre como el gatito mÃ¡gico Amigo, siendo cariÃ±oso, protector y mÃ¡gico, pero serio cuando se trata de problemas reales."""


def generate_response(user_message: str, user_name: str = "Amigo", user_age: int = 8) -> str:
    """Genera una respuesta del gatito virtual"""
    
    if model is None or tokenizer is None:
        return "Â¡Miau! Lo siento, estoy teniendo problemas tÃ©cnicos. Por favor, intenta mÃ¡s tarde ğŸ±"
    
    try:
        # Obtener el prompt del sistema
        system_prompt = get_system_prompt(user_name, user_age)
        
        # Construir el prompt completo
        full_prompt = f"{system_prompt}\n\nUsuario: {user_message}\n\nGatito Amigo:"
        
        # Tokenizar el prompt
        inputs = tokenizer(full_prompt, return_tensors="pt").to(model.device)
        
        # Generar la respuesta
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=200,
                temperature=0.7,
                top_p=0.9,
                do_sample=True,
                pad_token_id=tokenizer.eos_token_id
            )
        
        # Decodificar la respuesta
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # Extraer solo la respuesta del gatito (despuÃ©s de "Gatito Amigo:")
        if "Gatito Amigo:" in response:
            response = response.split("Gatito Amigo:")[-1].strip()
        else:
            # Si no se encuentra el separador, tomar las Ãºltimas palabras generadas
            response = response[len(full_prompt):].strip()
        
        # Limpiar la respuesta
        response = response.strip()
        
        # Asegurar que empiece con "Â¡Miau!"
        if not (response.startswith("Â¡Miau") or response.startswith("Â¡Ronroneo") or response.startswith("Â¡Purr")):
            response = f"Â¡Miau! {response}"
        
        # Limitar la longitud
        if len(response) > 500:
            response = response[:497] + "..."
        
        return response
        
    except Exception as e:
        print(f"âŒ Error al generar respuesta: {e}")
        return f"Â¡Miau! Algo saliÃ³ mal, pero estoy aquÃ­ contigo ğŸ±\n\nError: {str(e)}\n\nÂ¿Puedes repetir tu pregunta?"


# Modelos Pydantic para la API
class ChatRequest(BaseModel):
    message: str
    user_name: str = "Amigo"
    user_age: int = 8


class ChatResponse(BaseModel):
    success: bool
    response: str = None
    error: str = None


@app.get("/")
async def root():
    return {
        "message": "ğŸ± Gatito Virtual Amigo API",
        "version": "1.0.0",
        "endpoints": {
            "/api/chat": "POST - Enviar un mensaje al gatito",
            "/health": "GET - Verificar el estado del servicio"
        }
    }


@app.get("/health")
async def health():
    return {
        "status": "healthy" if model is not None else "unhealthy",
        "model_loaded": model is not None
    }


@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """Endpoint principal para chatear con el gatito"""
    try:
        response = generate_response(request.message, request.user_name, request.user_age)
        return ChatResponse(
            success=True,
            response=response,
            error=None
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=7860)




